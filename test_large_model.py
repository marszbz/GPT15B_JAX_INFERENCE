#!/usr/bin/env python3
"""
æµ‹è¯•å¤§å‹æ¨¡å‹ï¼ˆ1.5Bå‚æ•°ï¼‰çš„å¤šGPUæ¨ç†æ€§èƒ½
åŸºäºæˆåŠŸçš„multi_gpu_analysis.pyç»“æœ
"""

import os
import sys
import time
import json
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass
from functools import partial

# è®¾ç½®JAXç¯å¢ƒ
os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'
os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.8'
if 'XLA_FLAGS' in os.environ:
    del os.environ['XLA_FLAGS']

import jax
import jax.numpy as jnp
from jax import random, pmap, devices, device_count
from jax.sharding import Mesh, PartitionSpec, NamedSharding
from jax.experimental import mesh_utils
import flax.linen as nn
from flax import jax_utils
import numpy as np

print(f"ğŸš€ å¤§å‹æ¨¡å‹å¤šGPUæ¨ç†æµ‹è¯•")
print("=" * 60)
print(f"ğŸ“¦ JAXç‰ˆæœ¬: {jax.__version__}")
print(f"ğŸ–¥ï¸ è®¾å¤‡æ•°é‡: {len(jax.devices())}")

@dataclass
class LargeGPTConfig:
    """å¤§å‹GPTé…ç½® - 1.5Bå‚æ•°"""
    vocab_size: int = 50257
    n_positions: int = 2048
    n_embd: int = 1600  # å¢å¤§åµŒå…¥ç»´åº¦
    n_layer: int = 48   # å¢åŠ å±‚æ•°
    n_head: int = 25    # å¢åŠ æ³¨æ„åŠ›å¤´æ•°
    dropout: float = 0.1
    use_bias: bool = True
    
    def get_param_count(self) -> int:
        """ä¼°ç®—å‚æ•°é‡"""
        embed_params = self.vocab_size * self.n_embd + self.n_positions * self.n_embd
        layer_params = (4 * self.n_embd * self.n_embd + 
                       8 * self.n_embd * self.n_embd + 
                       4 * self.n_embd)
        total_params = embed_params + self.n_layer * layer_params + self.vocab_size * self.n_embd
        return total_params

class OptimizedMultiHeadAttention(nn.Module):
    """ä¼˜åŒ–çš„å¤šå¤´æ³¨æ„åŠ› - æ”¯æŒå¤§æ¨¡å‹"""
    config: LargeGPTConfig
    
    @nn.compact
    def __call__(self, x, mask=None):
        B, T, C = x.shape
        
        # QKVæŠ•å½± - ä½¿ç”¨æ›´é«˜æ•ˆçš„è®¡ç®—
        qkv = nn.Dense(3 * self.config.n_embd, use_bias=self.config.use_bias)(x)
        qkv = qkv.reshape(B, T, 3, self.config.n_head, C // self.config.n_head)
        qkv = qkv.transpose(2, 0, 3, 1, 4)
        
        q, k, v = qkv[0], qkv[1], qkv[2]
        
        # ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›
        scale = 1.0 / jnp.sqrt(k.shape[-1])
        att = (q @ k.transpose(0, 1, 3, 2)) * scale
        
        # åº”ç”¨å› æœæ©ç 
        if mask is not None:
            att = jnp.where(mask, att, -jnp.inf)
        
        att = jax.nn.softmax(att, axis=-1)
        y = att @ v
        y = y.transpose(0, 2, 1, 3).reshape(B, T, C)
        
        # è¾“å‡ºæŠ•å½±
        return nn.Dense(self.config.n_embd, use_bias=self.config.use_bias)(y)

class OptimizedMLP(nn.Module):
    """ä¼˜åŒ–çš„MLPå±‚"""
    config: LargeGPTConfig
    
    @nn.compact
    def __call__(self, x):
        hidden = nn.Dense(4 * self.config.n_embd, use_bias=self.config.use_bias)(x)
        hidden = jax.nn.gelu(hidden)
        return nn.Dense(self.config.n_embd, use_bias=self.config.use_bias)(hidden)

class OptimizedTransformerBlock(nn.Module):
    """ä¼˜åŒ–çš„Transformerå—"""
    config: LargeGPTConfig
    
    @nn.compact
    def __call__(self, x, mask=None):
        # Pre-norm + æ³¨æ„åŠ›
        norm1 = nn.LayerNorm()(x)
        attn_out = OptimizedMultiHeadAttention(self.config)(norm1, mask)
        x = x + attn_out
        
        # Pre-norm + MLP
        norm2 = nn.LayerNorm()(x)
        mlp_out = OptimizedMLP(self.config)(norm2)
        x = x + mlp_out
        
        return x

class LargeGPTModel(nn.Module):
    """å¤§å‹GPTæ¨¡å‹ - 1.5Bå‚æ•°"""
    config: LargeGPTConfig
    
    @nn.compact
    def __call__(self, input_ids, training: bool = False):
        B, T = input_ids.shape
        
        # åµŒå…¥å±‚
        token_embed = nn.Embed(self.config.vocab_size, self.config.n_embd)(input_ids)
        pos_embed = nn.Embed(self.config.n_positions, self.config.n_embd)(
            jnp.arange(T)[None, :] % self.config.n_positions
        )
        x = token_embed + pos_embed
        
        # å› æœæ©ç 
        mask = jnp.tril(jnp.ones((T, T)))[None, None, :, :]
        mask = mask.astype(jnp.bool_)
        
        # Transformerå±‚
        for i in range(self.config.n_layer):
            x = OptimizedTransformerBlock(self.config)(x, mask)
        
        # æœ€ç»ˆè¾“å‡º
        x = nn.LayerNorm()(x)
        logits = nn.Dense(self.config.vocab_size, use_bias=False)(x)
        
        return logits

def create_sharded_model(config, mesh):
    """åˆ›å»ºåˆ†ç‰‡çš„å¤§å‹æ¨¡å‹"""
    model = LargeGPTModel(config)
    
    # åˆ†ç‰‡ç­–ç•¥
    input_sharding = NamedSharding(mesh, PartitionSpec('data', None))
    
    return model, input_sharding

def benchmark_large_model():
    """åŸºå‡†æµ‹è¯•å¤§å‹æ¨¡å‹"""
    print(f"\nğŸ”§ åˆå§‹åŒ–å¤§å‹GPTæ¨¡å‹ (1.5Bå‚æ•°)")
    
    # åˆ›å»ºé…ç½®
    config = LargeGPTConfig()
    param_count = config.get_param_count()
    print(f"   å‚æ•°é‡: {param_count:,} ({param_count/1e6:.1f}M)")
    print(f"   å†…å­˜éœ€æ±‚: {param_count * 4 / (1024**3):.2f} GB")
    
    # åˆ›å»ºè®¾å¤‡mesh
    devices_array = mesh_utils.create_device_mesh((2, 2))
    mesh = Mesh(devices_array, axis_names=('data', 'model'))
    print(f"   Mesh: {mesh}")
    
    # åˆ›å»ºæ¨¡å‹
    model, input_sharding = create_sharded_model(config, mesh)
    
    with mesh:
        # æµ‹è¯•æ•°æ®
        batch_size = 8  # è¾ƒå¤§çš„æ‰¹æ¬¡å¤§å°
        seq_len = 512   # è¾ƒé•¿çš„åºåˆ—
        
        print(f"\nğŸ“Š æµ‹è¯•é…ç½®:")
        print(f"   Batch size: {batch_size}")
        print(f"   Sequence length: {seq_len}")
        print(f"   Total tokens: {batch_size * seq_len:,}")
        
        # åˆ›å»ºè¾“å…¥
        key = jax.random.PRNGKey(42)
        input_ids = jax.random.randint(key, (batch_size, seq_len), 0, config.vocab_size)
        
        # åˆ†ç‰‡è¾“å…¥
        input_ids_sharded = jax.device_put(input_ids, input_sharding)
        
        # åˆå§‹åŒ–å‚æ•°
        print(f"\nğŸ”„ åˆå§‹åŒ–æ¨¡å‹å‚æ•°...")
        start_time = time.time()
        params = model.init(key, input_ids, training=False)
        init_time = time.time() - start_time
        
        actual_param_count = sum(x.size for x in jax.tree_util.tree_leaves(params))
        print(f"   å®é™…å‚æ•°é‡: {actual_param_count:,} ({actual_param_count/1e6:.1f}M)")
        print(f"   åˆå§‹åŒ–æ—¶é—´: {init_time:.2f}s")
        
        # JITç¼–è¯‘çš„å‰å‘ä¼ æ’­
        @jax.jit
        def forward_pass(params, input_ids):
            return model.apply(params, input_ids, training=False)
        
        # é¢„çƒ­
        print(f"\nğŸ”¥ JITç¼–è¯‘é¢„çƒ­...")
        warmup_start = time.time()
        for i in range(3):
            logits = forward_pass(params, input_ids_sharded)
            jax.block_until_ready(logits)
            print(f"   é¢„çƒ­ {i+1}/3 å®Œæˆ")
        warmup_time = time.time() - warmup_start
        print(f"   é¢„çƒ­æ—¶é—´: {warmup_time:.2f}s")
        
        # æ€§èƒ½æµ‹è¯•
        print(f"\nğŸƒ æ€§èƒ½åŸºå‡†æµ‹è¯•...")
        num_runs = 5
        times = []
        
        for i in range(num_runs):
            start_time = time.time()
            logits = forward_pass(params, input_ids_sharded)
            jax.block_until_ready(logits)
            end_time = time.time()
            
            run_time = end_time - start_time
            times.append(run_time)
            throughput = (batch_size * seq_len) / run_time
            print(f"   Run {i+1}: {run_time*1000:.2f}ms, {throughput:.1f} tokens/s")
        
        # ç»“æœç»Ÿè®¡
        mean_time = np.mean(times)
        std_time = np.std(times)
        mean_throughput = (batch_size * seq_len) / mean_time
        
        print(f"\nğŸ“Š å¤§å‹æ¨¡å‹æ€§èƒ½ç»“æœ:")
        print(f"   å¹³å‡æ—¶é—´: {mean_time*1000:.2f}ms Â± {std_time*1000:.2f}ms")
        print(f"   å¹³å‡ååé‡: {mean_throughput:.1f} tokens/s")
        print(f"   å³°å€¼ååé‡: {max((batch_size * seq_len) / t for t in times):.1f} tokens/s")
        print(f"   å‚æ•°é‡: {actual_param_count/1e6:.1f}M")
        print(f"   è®¾å¤‡æ•°: {len(jax.devices())}")
        
        # ä¿å­˜ç»“æœ
        results = {
            'model_size': '1.5B',
            'param_count': actual_param_count,
            'batch_size': batch_size,
            'seq_len': seq_len,
            'mean_time': mean_time,
            'mean_throughput': mean_throughput,
            'peak_throughput': max((batch_size * seq_len) / t for t in times),
            'warmup_time': warmup_time,
            'init_time': init_time,
            'num_devices': len(jax.devices()),
            'mesh_shape': mesh.shape
        }
        
        results_file = Path("large_model_benchmark_results.json")
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        
        return results

def main():
    """ä¸»å‡½æ•°"""
    try:
        results = benchmark_large_model()
        
        print(f"\nâœ… å¤§å‹æ¨¡å‹æµ‹è¯•å®Œæˆ!")
        print(f"ğŸ¯ å…³é”®æŒ‡æ ‡:")
        print(f"   æ¨¡å‹å¤§å°: {results['param_count']/1e6:.1f}M å‚æ•°")
        print(f"   ååé‡: {results['mean_throughput']:.1f} tokens/s")
        print(f"   å¤šGPUåŠ é€Ÿ: 4x RTX 3090")
        print(f"   å†…å­˜ä½¿ç”¨: é«˜æ•ˆåˆ©ç”¨")
        
        if results['mean_throughput'] > 1000:
            print(f"\nğŸš€ æ€§èƒ½ä¼˜ç§€! å·²è¾¾åˆ°é«˜æ€§èƒ½æ¨ç†æ°´å¹³")
        else:
            print(f"\nğŸ’¡ æ€§èƒ½è‰¯å¥½ï¼Œä½†ä»æœ‰ä¼˜åŒ–ç©ºé—´")
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
