#!/bin/bash
# GPT-1.5B JAX æ¨ç†æ€§èƒ½æµ‹è¯•å¯åŠ¨è„šæœ¬ (Ubuntuç‰ˆæœ¬)
# =========================================

echo "ğŸš€ GPT-1.5B JAX æ¨ç†æ€§èƒ½æµ‹è¯•å¯åŠ¨è„šæœ¬"
echo "========================================="

# æ£€æŸ¥condaæ˜¯å¦å®‰è£…
if ! command -v conda &> /dev/null; then
    echo "âŒ Condaæœªå®‰è£…æˆ–æœªæ·»åŠ åˆ°PATH"
    echo "è¯·å…ˆå®‰è£…Minicondaæˆ–Anaconda"
    exit 1
fi

echo "ğŸ“¦ æ¿€æ´»condaç¯å¢ƒ..."
source "$(conda info --base)/etc/profile.d/conda.sh"
conda activate gpt_inference
if [ $? -ne 0 ]; then
    echo "âŒ ç¯å¢ƒæ¿€æ´»å¤±è´¥ï¼Œè¯·å…ˆåˆ›å»ºç¯å¢ƒ:"
    echo "conda env create -f environment.yml"
    exit 1
fi

echo "ğŸ” æ£€æŸ¥JAXå’ŒGPUç¯å¢ƒ..."
python -c "import jax; print(f'JAXç‰ˆæœ¬: {jax.__version__}'); devices = jax.devices(); print(f'GPUæ•°é‡: {len(devices)}'); [print(f'  GPU {i}: {device}') for i, device in enumerate(devices)]"
if [ $? -ne 0 ]; then
    echo "âŒ JAXæˆ–GPUæ£€æŸ¥å¤±è´¥"
    exit 1
fi

echo "ğŸ“Š æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶..."
if [ ! -f "datasets/benchmark_dataset_config_0.jsonl" ]; then
    echo "âŒ æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨"
    exit 1
fi

echo "ğŸ“ åˆ›å»ºç»“æœç›®å½•..."
mkdir -p results

echo "âš¡ å¼€å§‹è¿è¡ŒåŸºå‡†æµ‹è¯•..."
echo ""
python main.py --max-samples 10 --show-gpu-info

if [ $? -eq 0 ]; then
    echo ""
    echo "âœ… æµ‹è¯•å®Œæˆï¼"
    echo "ğŸ“ æŸ¥çœ‹resultsç›®å½•è·å–è¯¦ç»†ç»“æœ"
    echo ""
    echo "ğŸ” å¿«é€ŸæŸ¥çœ‹ç»“æœ:"
    if [ -f "results/benchmark_summary.txt" ]; then
        echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        cat results/benchmark_summary.txt
        echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    fi
else
    echo ""
    echo "âŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯"
    echo "ğŸ’¡ å¸¸è§é—®é¢˜æ’æŸ¥:"
    echo "   1. æ£€æŸ¥CUDAé©±åŠ¨æ˜¯å¦æ­£ç¡®å®‰è£…"
    echo "   2. æ£€æŸ¥JAXæ˜¯å¦èƒ½æ­£ç¡®è¯†åˆ«GPU"
    echo "   3. æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶æ˜¯å¦å­˜åœ¨"
fi

echo ""
echo "æŒ‰Enteré”®ç»§ç»­..."
read
