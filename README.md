# GPT-1.5B JAX æ¨ç†æ€§èƒ½æµ‹è¯•é¡¹ç›®

åŸºäº JAX å®ç°çš„ GPT-1.5B æ¨¡å‹æ¨ç†æ€§èƒ½æµ‹è¯•ï¼Œæ”¯æŒå›¾åˆ†å‰²å’Œå¤š GPU å¹¶è¡ŒåŒ–ï¼Œä¸“ä¸º Ubuntu + 4x RTX 3080 GPU ç¯å¢ƒä¼˜åŒ–ã€‚

## ğŸš€ é¡¹ç›®ç‰¹æ€§

- âœ… å®Œæ•´çš„ JAX/Flax GPT-1.5B æ¨¡å‹å®ç°
- âœ… å›¾åˆ†å‰²æŠ€æœ¯æ”¯æŒå¤š GPU å¹¶è¡Œæ¨ç†
- âœ… è‡ªåŠ¨åŠ è½½å’Œå¤„ç†æ‚¨çš„ JSONL æ•°æ®é›†
- âœ… è¯¦ç»†çš„æ€§èƒ½åŸºå‡†æµ‹è¯•å’ŒæŠ¥å‘Š
- âœ… Ubuntu ç³»ç»Ÿä¼˜åŒ–
- âœ… æ”¯æŒ CUDA 11.8 + JAX 0.6.1

## ğŸ“‹ ç¯å¢ƒè¦æ±‚

- Ubuntu 20.04/22.04 LTS
- Python 3.8-3.10
- CUDA 11.8
- 4x NVIDIA RTX 3080 GPU
- JAX 0.6.1
- Conda/Miniconda

## ğŸ› ï¸ å¿«é€Ÿå¼€å§‹

### 1. å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®

```bash
# å¦‚æœå·²ç»æœ‰é¡¹ç›®æ–‡ä»¶ï¼Œç›´æ¥è¿›å…¥ç›®å½•
cd /path/to/gpt15b-jax-inference
```

### 2. ä¸€é”®ç¯å¢ƒè®¾ç½®

```bash
# ä½¿ç”¨Makefileå¿«é€Ÿå®‰è£…
make install

# æˆ–æ‰‹åŠ¨è¿è¡Œç¯å¢ƒè®¾ç½®è„šæœ¬
chmod +x setup_environment.sh
./setup_environment.sh
```

è¿™ä¸ªè„šæœ¬ä¼šè‡ªåŠ¨ï¼š

- åˆ›å»º conda ç¯å¢ƒ
- å®‰è£… JAX (CUDA 11.8 ç‰ˆæœ¬)
- å®‰è£…æ‰€æœ‰ä¾èµ–åŒ…
- éªŒè¯ GPU è®¾ç½®

### 3. è¿è¡Œæ¨ç†æµ‹è¯•

```bash
# ä½¿ç”¨Makefileè¿è¡Œæµ‹è¯•
make test

# æˆ–æ‰‹åŠ¨è¿è¡ŒåŸºå‡†æµ‹è¯•
chmod +x scripts/run_benchmark.sh
./scripts/run_benchmark.sh
```

### 4. æ‰‹åŠ¨è¿è¡Œï¼ˆå¯é€‰ï¼‰

```powershell
# æ¿€æ´»ç¯å¢ƒ
conda activate gpt_inference

# è¿è¡Œæµ‹è¯•
python main.py

# æŸ¥çœ‹æ‰€æœ‰é€‰é¡¹
python main.py --help
```

## ğŸ“Š æ•°æ®é›†æ ¼å¼

é¡¹ç›®ä½¿ç”¨æ‚¨æä¾›çš„ JSONL æ ¼å¼æ•°æ®é›†ï¼š

```json
{
  "id": "sample_0_0",
  "config_id": 0,
  "prompt": "Alberta Legislature Building...",
  "prompt_length": 32,
  "generation_length": 32,
  "source_type": "synthetic",
  "metadata": {
    "created_at": "2025-05-30",
    "tokenizer": "gpt2",
    "prompt_tokens": 32
  }
}
```

æ”¯æŒçš„é…ç½®ï¼š

- **é…ç½® 0**: 32 tokens prompt â†’ 32 tokens ç”Ÿæˆ
- **é…ç½® 1**: 32 tokens prompt â†’ 64 tokens ç”Ÿæˆ
- **é…ç½® 2**: 128 tokens prompt â†’ 32 tokens ç”Ÿæˆ
- **é…ç½® 3**: 128 tokens prompt â†’ 64 tokens ç”Ÿæˆ

## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬æµ‹è¯•

```bash
python main.py
```

### æµ‹è¯•ç‰¹å®šé…ç½®

```bash
# åªæµ‹è¯•é…ç½®0å’Œ1
python main.py --config 0,1

# è‡ªå®šä¹‰æ ·æœ¬æ•°
python main.py --max-samples 5

# æ˜¾ç¤ºGPUè¯¦ç»†ä¿¡æ¯
python main.py --show-gpu-info
```

### è‡ªå®šä¹‰è¾“å‡ºç›®å½•

```bash
python main.py --output-dir my_results
```

### ä½¿ç”¨ Makefile å‘½ä»¤

```bash
# æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨å‘½ä»¤
make help

# å®Œæ•´åŸºå‡†æµ‹è¯•
make benchmark

# æ£€æŸ¥GPUç¯å¢ƒ
make check-gpu

# ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
make report
```

## ğŸ“ é¡¹ç›®ç»“æ„

```text
gpt15b-jax-inference/
â”œâ”€â”€ main.py                    # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ requirements.txt           # Pythonä¾èµ–
â”œâ”€â”€ environment.yml            # Condaç¯å¢ƒé…ç½®
â”œâ”€â”€ Makefile                   # Ubuntuå‘½ä»¤é›†åˆ
â”œâ”€â”€ setup_environment.sh       # ç¯å¢ƒå®‰è£…è„šæœ¬
â”œâ”€â”€ README.md                  # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ UBUNTU_INSTALL.md          # Ubuntuå®‰è£…æŒ‡å—
â”œâ”€â”€ upload_to_github_ubuntu.sh # GitHubä¸Šä¼ è„šæœ¬
â”œâ”€â”€ src/                       # æºä»£ç 
â”‚   â”œâ”€â”€ models/               # æ¨¡å‹å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ gpt_model.py      # GPT-1.5Bæ¨¡å‹å’Œå›¾åˆ†å‰²
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/                 # æ•°æ®å¤„ç†
â”‚   â”‚   â”œâ”€â”€ dataset_loader.py # æ•°æ®é›†åŠ è½½å™¨
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ inference/            # æ¨ç†å’Œæµ‹è¯•
â”‚   â”‚   â”œâ”€â”€ benchmark.py      # æ€§èƒ½åŸºå‡†æµ‹è¯•
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ utils/                # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ gpu_utils.py      # GPUå·¥å…·
â”‚       â”œâ”€â”€ results.py        # ç»“æœå¤„ç†
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ datasets/                 # æ•°æ®é›†æ–‡ä»¶
â”‚   â”œâ”€â”€ benchmark_dataset_config_0.jsonl
â”‚   â”œâ”€â”€ benchmark_dataset_config_1.jsonl
â”‚   â”œâ”€â”€ benchmark_dataset_config_2.jsonl
â”‚   â””â”€â”€ benchmark_dataset_config_3.jsonl
â”œâ”€â”€ scripts/                  # è¿è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ setup_environment.sh  # ç¯å¢ƒè®¾ç½®è„šæœ¬
â”‚   â””â”€â”€ run_benchmark.sh      # åŸºå‡†æµ‹è¯•è„šæœ¬
â”œâ”€â”€ configs/                  # é…ç½®æ–‡ä»¶ç›®å½•
â”œâ”€â”€ results/                  # æµ‹è¯•ç»“æœè¾“å‡º
â””â”€â”€ tests/                    # å•å…ƒæµ‹è¯•ï¼ˆå¾…æ·»åŠ ï¼‰
```

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

æµ‹è¯•ä¼šç”Ÿæˆä»¥ä¸‹æ€§èƒ½æŒ‡æ ‡ï¼š

- **æ¨ç†å»¶è¿Ÿ**: æ¯æ¬¡æ¨ç†çš„æ€»æ—¶é—´
- **ååé‡**: tokens/ç§’
- **æ¯ token å»¶è¿Ÿ**: å¹³å‡æ¯ä¸ª token çš„ç”Ÿæˆæ—¶é—´
- **GPU åˆ©ç”¨ç‡**: å¤š GPU å¹¶è¡Œæ•ˆç‡
- **å†…å­˜ä½¿ç”¨**: GPU å†…å­˜å ç”¨æƒ…å†µ

## ğŸ“Š ç»“æœè¾“å‡º

### JSON è¯¦ç»†ç»“æœ

```json
{
  "benchmark_info": {
    "total_execution_time": 45.67,
    "configs_tested": 4,
    "gpu_count": 4,
    "jax_version": "0.6.1"
  },
  "results": {
    "0": {
      "avg_throughput": 156.3,
      "avg_inference_time": 0.205,
      "samples_tested": 10
    }
  }
}
```

### æ–‡æœ¬æŠ¥å‘Š

```
GPT-1.5B JAX æ¨ç†æ€§èƒ½æµ‹è¯•æŠ¥å‘Š
==================================

æµ‹è¯•æ—¶é—´: 2025-06-11 13:45:23
æ€»æ‰§è¡Œæ—¶é—´: 45.67ç§’
GPUæ•°é‡: 4
JAXç‰ˆæœ¬: 0.6.1

é…ç½® 0:
  å¹³å‡æ¨ç†æ—¶é—´: 0.205Â±0.015s
  å¹³å‡ååé‡: 156.3 tokens/s

æ€»ä½“æ€§èƒ½ç»Ÿè®¡:
  æœ€é«˜ååé‡: 198.5 tokens/s
  æœ€ä½å»¶è¿Ÿ: 0.003s/token
```

## ğŸ”§ å›¾åˆ†å‰²æŠ€æœ¯

é¡¹ç›®å®ç°äº†å…ˆè¿›çš„å›¾åˆ†å‰²ç­–ç•¥ï¼š

- **å±‚çº§å¹¶è¡Œ**: 48 ä¸ª Transformer å±‚åˆ†å¸ƒåˆ° 4 ä¸ª GPU
- **æ³¨æ„åŠ›åˆ†å‰²**: 25 ä¸ªæ³¨æ„åŠ›å¤´å¹¶è¡Œè®¡ç®—
- **å‚æ•°åˆ†ç‰‡**: å¤§çŸ©é˜µæŒ‰ç»´åº¦æ™ºèƒ½åˆ†ç‰‡
- **æµæ°´çº¿å¹¶è¡Œ**: å‡å°‘ GPU é—²ç½®æ—¶é—´

## âš¡ æ€§èƒ½ä¼˜åŒ–

- JAX JIT ç¼–è¯‘åŠ é€Ÿ
- å†…å­˜é«˜æ•ˆçš„å‚æ•°åˆ†ç‰‡
- ä¼˜åŒ–çš„ CUDA å†…æ ¸
- è‡ªé€‚åº”æ‰¹æ¬¡å¤§å°

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **JAX å®‰è£…å¤±è´¥**

   ```bash
   # æ‰‹åŠ¨å®‰è£…JAX CUDAç‰ˆæœ¬
   pip install jax==0.6.1 jaxlib==0.6.1+cuda118 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html
   ```

2. **GPU æœªæ£€æµ‹åˆ°**

   ```bash
   # æ£€æŸ¥CUDAå®‰è£…
   nvidia-smi
   nvcc --version

   # éªŒè¯JAX GPU
   python -c "import jax; print(jax.devices())"
   ```

3. **å†…å­˜ä¸è¶³**
   - å‡å°‘ `--max-samples` å‚æ•°
   - æ£€æŸ¥ GPU å†…å­˜ä½¿ç”¨: `nvidia-smi`

### è¯Šæ–­å‘½ä»¤

```bash
# æ£€æŸ¥ç¯å¢ƒ
python -c "import jax, flax, numpy; print('âœ… æ‰€æœ‰åŒ…æ­£å¸¸')"

# æ£€æŸ¥GPU
python -c "import jax; print(f'GPUæ•°é‡: {len(jax.devices())}')"

# æ£€æŸ¥æ•°æ®é›†
python -c "import os; print('æ•°æ®é›†æ–‡ä»¶:', [f for f in os.listdir('datasets') if f.endswith('.jsonl')])"

# ä½¿ç”¨Makefileå‘½ä»¤
make check-gpu    # æ£€æŸ¥GPUç¯å¢ƒ
make status       # æŸ¥çœ‹é¡¹ç›®çŠ¶æ€
make help         # æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨å‘½ä»¤
```

## ğŸ“ æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜ï¼š

1. æ£€æŸ¥ç¯å¢ƒè¦æ±‚æ˜¯å¦æ»¡è¶³
2. è¿è¡Œè¯Šæ–­å‘½ä»¤
3. æŸ¥çœ‹é”™è¯¯æ—¥å¿—
4. ç¡®è®¤æ•°æ®é›†æ–‡ä»¶å®Œæ•´

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ã€‚

---

ğŸ¯ **å¼€å§‹ä½¿ç”¨**: è¿è¡Œ `scripts\setup_environment.bat` ç„¶å `scripts\run_benchmark.bat`

ğŸš€ **å¿«é€Ÿæµ‹è¯•**: `python main.py --config 0 --max-samples 3`
