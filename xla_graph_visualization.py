#!/usr/bin/env python3
"""
XLAç¼–è¯‘å™¨å›¾ä¼˜åŒ–å’Œå›¾åˆ†å‰²å¯è§†åŒ–ç³»ç»Ÿ
å±•ç¤ºXLAå¦‚ä½•è¿›è¡Œå›¾ä¼˜åŒ–å’Œå¿«é€Ÿæ•°å­¦è¿ç®—çš„è¯¦ç»†è¿‡ç¨‹
"""

import os
import sys
import time
import json
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass
from functools import partial
import graphviz

# è®¾ç½®JAXç¯å¢ƒ
os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'
os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.8'
os.environ['XLA_FLAGS'] = '--xla_gpu_enable_fast_math=true --xla_dump_to=/tmp/xla_dumps'

try:
    import jax
    import jax.numpy as jnp
    from jax import random, devices
    from jax.sharding import Mesh, PartitionSpec, NamedSharding
    from jax.experimental import mesh_utils
    import flax.linen as nn
    import numpy as np
    print(f"âœ… JAX {jax.__version__} å›¾ä¼˜åŒ–æ¨¡å¼åŠ è½½")
except ImportError as e:
    print(f"âŒ JAXå¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

print("ğŸ” XLAç¼–è¯‘å™¨å›¾ä¼˜åŒ–å’Œå›¾åˆ†å‰²å¯è§†åŒ–")
print("=" * 60)

@dataclass
class XLAOptimizationConfig:
    """XLAä¼˜åŒ–é…ç½®"""
    enable_fast_math: bool = True
    enable_graph_fusion: bool = True 
    enable_memory_optimization: bool = True
    dump_hlo_graphs: bool = True
    optimization_level: int = 3

class XLAGraphVisualizer:
    """XLAå›¾ä¼˜åŒ–å¯è§†åŒ–å™¨"""
    
    def __init__(self, config: XLAOptimizationConfig):
        self.config = config
        self.optimization_stages = []
        self.graph_partitions = {}
        
    def analyze_xla_optimizations(self):
        """åˆ†æXLAä¼˜åŒ–è¿‡ç¨‹"""
        print("\nğŸ“Š XLAç¼–è¯‘å™¨ä¼˜åŒ–åˆ†æ")
        print("-" * 40)
        
        optimizations = {
            "å›¾èåˆä¼˜åŒ–": {
                "æè¿°": "å°†å¤šä¸ªå°æ“ä½œèåˆä¸ºå¤§æ“ä½œ",
                "ç¤ºä¾‹": ["çŸ©é˜µä¹˜æ³•+åç½®åŠ æ³•èåˆ", "æ¿€æ´»å‡½æ•°èåˆ", "æ‰¹é‡å½’ä¸€åŒ–èåˆ"],
                "æ€§èƒ½æå‡": "å‡å°‘å†…å­˜è®¿é—®ï¼Œæé«˜ç¼“å­˜åˆ©ç”¨ç‡"
            },
            "å¿«é€Ÿæ•°å­¦ä¼˜åŒ–": {
                "æè¿°": "ä½¿ç”¨è¿‘ä¼¼ç®—æ³•åŠ é€Ÿæ•°å­¦è¿ç®—",
                "ç¤ºä¾‹": ["å¿«é€Ÿå€’æ•°å¹³æ–¹æ ¹", "è¿‘ä¼¼GELU", "èåˆä¹˜åŠ è¿ç®—"],
                "æ€§èƒ½æå‡": "2-5xåŠ é€Ÿæ•°å­¦è¿ç®—"
            },
            "å†…å­˜å¸ƒå±€ä¼˜åŒ–": {
                "æè¿°": "ä¼˜åŒ–å¼ é‡å†…å­˜å¸ƒå±€æé«˜è®¿é—®æ•ˆç‡",
                "ç¤ºä¾‹": ["åˆ—ä¸»åºè½¬è¡Œä¸»åº", "å†…å­˜å¯¹é½", "é¢„å–ä¼˜åŒ–"],
                "æ€§èƒ½æå‡": "å‡å°‘å†…å­˜å¸¦å®½ç“¶é¢ˆ"
            },
            "å¾ªç¯ä¼˜åŒ–": {
                "æè¿°": "ä¼˜åŒ–å¾ªç¯ç»“æ„å’Œå‘é‡åŒ–",
                "ç¤ºä¾‹": ["å¾ªç¯å±•å¼€", "å‘é‡åŒ–", "å¹¶è¡ŒåŒ–"],
                "æ€§èƒ½æå‡": "å……åˆ†åˆ©ç”¨SIMDæŒ‡ä»¤"
            }
        }
        
        for name, details in optimizations.items():
            print(f"\nğŸ”§ {name}:")
            print(f"   ğŸ“ {details['æè¿°']}")
            print(f"   ğŸ’¡ ç¤ºä¾‹:")
            for example in details['ç¤ºä¾‹']:
                print(f"      â€¢ {example}")
            print(f"   âš¡ æ€§èƒ½æå‡: {details['æ€§èƒ½æå‡']}")
            
        return optimizations
    
    def demonstrate_graph_partitioning(self):
        """æ¼”ç¤ºå›¾åˆ†å‰²è¿‡ç¨‹"""
        print("\nğŸ”€ å›¾åˆ†å‰²ç­–ç•¥æ¼”ç¤º")
        print("-" * 40)
        
        # 4ä¸ªGPUçš„åˆ†å‰²ç­–ç•¥
        gpu_count = len(jax.devices())
        print(f"æ£€æµ‹åˆ° {gpu_count} ä¸ªGPUè®¾å¤‡")
        
        partitioning_strategies = {
            "æ•°æ®å¹¶è¡Œåˆ†å‰²": {
                "æ–¹å¼": "åœ¨batchç»´åº¦åˆ†ç‰‡",
                "ä¼˜åŠ¿": "ç®€å•å®ç°ï¼Œè‰¯å¥½æ‰©å±•æ€§",
                "é€‚ç”¨": "æ¨¡å‹è¾ƒå°ï¼Œå†…å­˜å……è¶³",
                "åˆ†ç‰‡": "PartitionSpec('data', None)"
            },
            "æ¨¡å‹å¹¶è¡Œåˆ†å‰²": {
                "æ–¹å¼": "åœ¨å‚æ•°ç»´åº¦åˆ†ç‰‡", 
                "ä¼˜åŠ¿": "æ”¯æŒè¶…å¤§æ¨¡å‹",
                "é€‚ç”¨": "æ¨¡å‹å·¨å¤§ï¼Œå•GPUè£…ä¸ä¸‹",
                "åˆ†ç‰‡": "PartitionSpec('model', None)"
            },
            "æµæ°´çº¿å¹¶è¡Œåˆ†å‰²": {
                "æ–¹å¼": "æŒ‰å±‚åˆ†å‰²åˆ°ä¸åŒGPU",
                "ä¼˜åŠ¿": "æœ€å¤§åŒ–GPUåˆ©ç”¨ç‡",
                "é€‚ç”¨": "æ·±å±‚ç½‘ç»œ",
                "åˆ†ç‰‡": "æŒ‰å±‚ç´¢å¼•åˆ†é…"
            },
            "æ··åˆå¹¶è¡Œåˆ†å‰²": {
                "æ–¹å¼": "æ•°æ®+æ¨¡å‹+æµæ°´çº¿ç»„åˆ",
                "ä¼˜åŠ¿": "æœ€ä¼˜æ€§èƒ½",
                "é€‚ç”¨": "è¶…å¤§è§„æ¨¡è®­ç»ƒ",
                "åˆ†ç‰‡": "2x2 Meshé…ç½®"
            }
        }
        
        for strategy, details in partitioning_strategies.items():
            print(f"\nğŸ“‹ {strategy}:")
            for key, value in details.items():
                print(f"   {key}: {value}")
                
        return partitioning_strategies
    
    def create_optimization_graph(self):
        """åˆ›å»ºä¼˜åŒ–è¿‡ç¨‹å¯è§†åŒ–å›¾"""
        print("\nğŸ“ˆ åˆ›å»ºXLAä¼˜åŒ–æµç¨‹å›¾")
        
        dot = graphviz.Digraph(comment='XLAä¼˜åŒ–æµç¨‹')
        dot.attr(rankdir='TB', size='12,8')
        
        # è¾“å…¥é˜¶æ®µ
        dot.node('input', 'JAXç¨‹åº\n(Python)', shape='box', style='filled', fillcolor='lightblue')
        
        # ç¼–è¯‘é˜¶æ®µ
        dot.node('jaxpr', 'JAXprä¸­é—´è¡¨ç¤º\n(å‡½æ•°å¼IR)', shape='box', style='filled', fillcolor='lightgreen')
        dot.node('hlo', 'HLOå›¾\n(é«˜çº§çº¿æ€§æ“ä½œ)', shape='box', style='filled', fillcolor='lightgreen')
        
        # ä¼˜åŒ–é˜¶æ®µ
        dot.node('fusion', 'å›¾èåˆä¼˜åŒ–\nâ€¢ æ“ä½œåˆå¹¶\nâ€¢ å†…å­˜ä¼˜åŒ–', shape='box', style='filled', fillcolor='yellow')
        dot.node('fastmath', 'å¿«é€Ÿæ•°å­¦ä¼˜åŒ–\nâ€¢ è¿‘ä¼¼ç®—æ³•\nâ€¢ èåˆè¿ç®—', shape='box', style='filled', fillcolor='yellow')
        dot.node('layout', 'å†…å­˜å¸ƒå±€ä¼˜åŒ–\nâ€¢ æ•°æ®é‡æ’\nâ€¢ ç¼“å­˜ä¼˜åŒ–', shape='box', style='filled', fillcolor='yellow')
        
        # åˆ†å‰²é˜¶æ®µ
        dot.node('partition', 'å›¾åˆ†å‰²\nâ€¢ è®¾å¤‡åˆ†é…\nâ€¢ é€šä¿¡ä¼˜åŒ–', shape='box', style='filled', fillcolor='orange')
        
        # ä»£ç ç”Ÿæˆ
        dot.node('codegen', 'CUDAä»£ç ç”Ÿæˆ\nâ€¢ å†…æ ¸èåˆ\nâ€¢ è°ƒåº¦ä¼˜åŒ–', shape='box', style='filled', fillcolor='lightcoral')
        dot.node('execution', 'GPUæ‰§è¡Œ\nâ€¢ å¹¶è¡Œè®¡ç®—\nâ€¢ å†…å­˜ç®¡ç†', shape='box', style='filled', fillcolor='lightcoral')
        
        # æ·»åŠ è¾¹
        dot.edge('input', 'jaxpr')
        dot.edge('jaxpr', 'hlo')
        dot.edge('hlo', 'fusion')
        dot.edge('fusion', 'fastmath')
        dot.edge('fastmath', 'layout')
        dot.edge('layout', 'partition')
        dot.edge('partition', 'codegen')
        dot.edge('codegen', 'execution')
        
        # ä¿å­˜å›¾
        output_path = Path("xla_optimization_flow")
        dot.render(output_path, format='png', cleanup=True)
        print(f"   ä¼˜åŒ–æµç¨‹å›¾å·²ä¿å­˜: {output_path}.png")
        
        return dot
    
    def demonstrate_fast_math(self):
        """æ¼”ç¤ºå¿«é€Ÿæ•°å­¦ä¼˜åŒ–"""
        print("\nâš¡ å¿«é€Ÿæ•°å­¦ä¼˜åŒ–æ¼”ç¤º")
        print("-" * 40)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        key = jax.random.PRNGKey(42)
        x = jax.random.normal(key, (1000, 1000))
        
        print("æµ‹è¯•æ¡ˆä¾‹: GELUæ¿€æ´»å‡½æ•°")
        print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
        
        # æ ‡å‡†GELU (ç²¾ç¡®ç‰ˆæœ¬)
        def standard_gelu(x):
            return 0.5 * x * (1 + jnp.tanh(jnp.sqrt(2 / jnp.pi) * (x + 0.044715 * x**3)))
        
        # å¿«é€ŸGELU (è¿‘ä¼¼ç‰ˆæœ¬)
        def fast_gelu(x):
            return jax.nn.gelu(x, approximate=True)
        
        # ç¼–è¯‘å‡½æ•°
        compiled_standard = jax.jit(standard_gelu)
        compiled_fast = jax.jit(fast_gelu)
        
        # é¢„çƒ­
        _ = compiled_standard(x).block_until_ready()
        _ = compiled_fast(x).block_until_ready()
        
        # æ€§èƒ½æµ‹è¯•
        runs = 10
        
        # æ ‡å‡†ç‰ˆæœ¬
        times_standard = []
        for _ in range(runs):
            start = time.time()
            result_standard = compiled_standard(x).block_until_ready()
            times_standard.append(time.time() - start)
        
        # å¿«é€Ÿç‰ˆæœ¬
        times_fast = []
        for _ in range(runs):
            start = time.time()
            result_fast = compiled_fast(x).block_until_ready()
            times_fast.append(time.time() - start)
        
        avg_standard = np.mean(times_standard) * 1000
        avg_fast = np.mean(times_fast) * 1000
        speedup = avg_standard / avg_fast
        
        print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”:")
        print(f"   æ ‡å‡†GELU: {avg_standard:.2f}ms")
        print(f"   å¿«é€ŸGELU: {avg_fast:.2f}ms")
        print(f"   åŠ é€Ÿæ¯”: {speedup:.2f}x")
        
        # ç²¾åº¦å¯¹æ¯”
        max_diff = jnp.max(jnp.abs(result_standard - result_fast))
        print(f"   æœ€å¤§è¯¯å·®: {max_diff:.6f}")
        print(f"   ç›¸å¯¹è¯¯å·®: {max_diff/jnp.max(jnp.abs(result_standard))*100:.4f}%")
        
        return {
            'standard_time': avg_standard,
            'fast_time': avg_fast,
            'speedup': speedup,
            'max_error': float(max_diff)
        }
    
    def analyze_graph_partitioning_example(self):
        """åˆ†æå…·ä½“çš„å›¾åˆ†å‰²ä¾‹å­"""
        print("\nğŸ” å…·ä½“å›¾åˆ†å‰²æ¡ˆä¾‹åˆ†æ")
        print("-" * 40)
        
        if len(jax.devices()) < 2:
            print("âš ï¸ éœ€è¦è‡³å°‘2ä¸ªGPUè®¾å¤‡è¿›è¡Œåˆ†å‰²æ¼”ç¤º")
            return None
            
        # åˆ›å»º2x2 mesh
        try:
            if len(jax.devices()) >= 4:
                mesh_devices = mesh_utils.create_device_mesh((2, 2))
                mesh = Mesh(mesh_devices, axis_names=('data', 'model'))
                print(f"âœ… åˆ›å»º2x2 mesh: {mesh.shape}")
            else:
                mesh_devices = mesh_utils.create_device_mesh((2, 1))
                mesh = Mesh(mesh_devices, axis_names=('data', 'model'))
                print(f"âœ… åˆ›å»º2x1 mesh: {mesh.shape}")
                
            # æ¼”ç¤ºä¸åŒçš„åˆ†ç‰‡ç­–ç•¥
            batch_size, seq_len, hidden_size = 8, 512, 768
            
            print(f"\nğŸ“Š åˆ†ç‰‡ç­–ç•¥å¯¹æ¯”:")
            print(f"   åŸå§‹å¼ é‡: ({batch_size}, {seq_len}, {hidden_size})")
            
            strategies = {
                "æ— åˆ†ç‰‡": PartitionSpec(),
                "æ•°æ®å¹¶è¡Œ": PartitionSpec('data', None, None),
                "æ¨¡å‹å¹¶è¡Œ": PartitionSpec(None, None, 'model'),
                "æ··åˆå¹¶è¡Œ": PartitionSpec('data', None, 'model')
            }
            
            for name, spec in strategies.items():
                print(f"   {name}: {spec}")
                if spec.rules:
                    print(f"     åˆ†ç‰‡ç»´åº¦: {[i for i, rule in enumerate(spec.rules) if rule is not None]}")
                
            # åˆ›å»ºç¤ºä¾‹å¼ é‡å¹¶åº”ç”¨åˆ†ç‰‡
            key = jax.random.PRNGKey(42)
            x = jax.random.normal(key, (batch_size, seq_len, hidden_size))
            
            with mesh:
                for name, spec in strategies.items():
                    if name == "æ— åˆ†ç‰‡":
                        continue
                    try:
                        sharding = NamedSharding(mesh, spec)
                        x_sharded = jax.device_put(x, sharding)
                        print(f"   âœ… {name}åˆ†ç‰‡æˆåŠŸ")
                    except Exception as e:
                        print(f"   âŒ {name}åˆ†ç‰‡å¤±è´¥: {e}")
                        
            return {
                'mesh_shape': mesh.shape,
                'mesh_axes': mesh.axis_names,
                'tensor_shape': x.shape,
                'strategies': list(strategies.keys())
            }
            
        except Exception as e:
            print(f"âŒ Meshåˆ›å»ºå¤±è´¥: {e}")
            return None
    
    def create_partition_visualization(self):
        """åˆ›å»ºåˆ†ç‰‡å¯è§†åŒ–å›¾"""
        print("\nğŸ¨ åˆ›å»ºå›¾åˆ†å‰²å¯è§†åŒ–")
        
        dot = graphviz.Digraph(comment='å›¾åˆ†å‰²ç­–ç•¥')
        dot.attr(rankdir='LR', size='14,10')
        
        # 4ä¸ªGPUè®¾å¤‡
        with dot.subgraph(name='cluster_gpus') as gpu_cluster:
            gpu_cluster.attr(label='4x RTX 3090 GPUs', style='dashed')
            gpu_cluster.node('gpu0', 'GPU 0\n(0,0)', shape='box', style='filled', fillcolor='lightblue')
            gpu_cluster.node('gpu1', 'GPU 1\n(0,1)', shape='box', style='filled', fillcolor='lightblue')
            gpu_cluster.node('gpu2', 'GPU 2\n(1,0)', shape='box', style='filled', fillcolor='lightblue')
            gpu_cluster.node('gpu3', 'GPU 3\n(1,1)', shape='box', style='filled', fillcolor='lightblue')
        
        # æ¨¡å‹ç»„ä»¶
        with dot.subgraph(name='cluster_model') as model_cluster:
            model_cluster.attr(label='GPT-1.5Bæ¨¡å‹ç»„ä»¶', style='dashed')
            model_cluster.node('embed', 'Embedding\n50257x1600', shape='ellipse', style='filled', fillcolor='lightgreen')
            model_cluster.node('attn', 'Multi-Head\nAttention\n25å¤´', shape='ellipse', style='filled', fillcolor='lightgreen')
            model_cluster.node('mlp', 'MLP\n1600â†’6400â†’1600', shape='ellipse', style='filled', fillcolor='lightgreen')
            model_cluster.node('norm', 'LayerNorm\n1600ç»´', shape='ellipse', style='filled', fillcolor='lightgreen')
        
        # åˆ†ç‰‡è¿æ¥
        dot.edge('embed', 'gpu0', label='è¯æ±‡è¡¨åˆ†ç‰‡', style='dashed', color='red')
        dot.edge('embed', 'gpu1', label='è¯æ±‡è¡¨åˆ†ç‰‡', style='dashed', color='red')
        
        dot.edge('attn', 'gpu0', label='æ³¨æ„åŠ›å¤´\n0-6', style='solid', color='blue')
        dot.edge('attn', 'gpu1', label='æ³¨æ„åŠ›å¤´\n7-12', style='solid', color='blue')
        dot.edge('attn', 'gpu2', label='æ³¨æ„åŠ›å¤´\n13-18', style='solid', color='blue')
        dot.edge('attn', 'gpu3', label='æ³¨æ„åŠ›å¤´\n19-24', style='solid', color='blue')
        
        dot.edge('mlp', 'gpu0', label='éšè—å±‚\n0-1599', style='dotted', color='green')
        dot.edge('mlp', 'gpu1', label='éšè—å±‚\n1600-3199', style='dotted', color='green')
        dot.edge('mlp', 'gpu2', label='éšè—å±‚\n3200-4799', style='dotted', color='green')
        dot.edge('mlp', 'gpu3', label='éšè—å±‚\n4800-6399', style='dotted', color='green')
        
        dot.edge('norm', 'gpu0', label='å¤åˆ¶', style='solid', color='black')
        dot.edge('norm', 'gpu1', label='å¤åˆ¶', style='solid', color='black')
        dot.edge('norm', 'gpu2', label='å¤åˆ¶', style='solid', color='black')
        dot.edge('norm', 'gpu3', label='å¤åˆ¶', style='solid', color='black')
        
        # ä¿å­˜å›¾
        output_path = Path("graph_partitioning")
        dot.render(output_path, format='png', cleanup=True)
        print(f"   åˆ†å‰²å¯è§†åŒ–å›¾å·²ä¿å­˜: {output_path}.png")
        
        return dot

def main():
    """ä¸»å‡½æ•° - XLAå›¾ä¼˜åŒ–å’Œåˆ†å‰²åˆ†æ"""
    config = XLAOptimizationConfig()
    visualizer = XLAGraphVisualizer(config)
    
    print(f"ğŸ¯ åˆ†æç›®æ ‡: ç†è§£XLAç¼–è¯‘å™¨çš„å›¾ä¼˜åŒ–å’Œå›¾åˆ†å‰²æœºåˆ¶")
    print(f"ğŸ’» è®¾å¤‡ä¿¡æ¯: {len(jax.devices())} ä¸ªGPUè®¾å¤‡")
    
    all_results = {}
    
    try:
        # 1. åˆ†æXLAä¼˜åŒ–
        optimizations = visualizer.analyze_xla_optimizations()
        all_results['optimizations'] = optimizations
        
        # 2. æ¼”ç¤ºå›¾åˆ†å‰²
        partitioning = visualizer.demonstrate_graph_partitioning()
        all_results['partitioning'] = partitioning
        
        # 3. å¿«é€Ÿæ•°å­¦æ¼”ç¤º
        fastmath_results = visualizer.demonstrate_fast_math()
        all_results['fastmath'] = fastmath_results
        
        # 4. å…·ä½“åˆ†å‰²æ¡ˆä¾‹
        partition_example = visualizer.analyze_graph_partitioning_example()
        all_results['partition_example'] = partition_example
        
        # 5. åˆ›å»ºå¯è§†åŒ–
        print(f"\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        optimization_graph = visualizer.create_optimization_graph()
        partition_graph = visualizer.create_partition_visualization()
        
        # 6. ä¿å­˜ç»“æœ
        results_file = Path("xla_analysis_results.json")
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜: {results_file}")
        
        # 7. æ€»ç»“
        print(f"\nğŸ¯ XLAå›¾ä¼˜åŒ–å’Œåˆ†å‰²åˆ†æå®Œæˆ!")
        print("=" * 60)
        print(f"ğŸ“Š å…³é”®å‘ç°:")
        print(f"   â€¢ XLAä¼˜åŒ–ç±»å‹: {len(optimizations)} ç§")
        print(f"   â€¢ åˆ†å‰²ç­–ç•¥: {len(partitioning)} ç§")
        if fastmath_results:
            print(f"   â€¢ å¿«é€Ÿæ•°å­¦åŠ é€Ÿ: {fastmath_results['speedup']:.2f}x")
        if partition_example:
            print(f"   â€¢ Meshé…ç½®: {partition_example['mesh_shape']}")
        print(f"   â€¢ å¯è§†åŒ–å›¾è¡¨: 2ä¸ªPNGæ–‡ä»¶")
        
        print(f"\nğŸ“‹ è¦ç‚¹æ€»ç»“:")
        print(f"   1. XLAç¼–è¯‘å™¨é€šè¿‡å¤šå±‚ä¼˜åŒ–æå‡æ€§èƒ½")
        print(f"   2. å›¾èåˆå‡å°‘å†…å­˜è®¿é—®ï¼Œæé«˜ç¼“å­˜æ•ˆç‡")
        print(f"   3. å¿«é€Ÿæ•°å­¦ç”¨è¿‘ä¼¼ç®—æ³•æ¢å–2-5xåŠ é€Ÿ")
        print(f"   4. å›¾åˆ†å‰²å®ç°å¤šGPUå¹¶è¡Œï¼Œæ”¯æŒè¶…å¤§æ¨¡å‹")
        print(f"   5. æ··åˆå¹¶è¡Œç­–ç•¥è¾¾åˆ°æœ€ä¼˜æ€§èƒ½")
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
