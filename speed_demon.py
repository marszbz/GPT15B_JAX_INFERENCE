#!/usr/bin/env python3
"""
ç»ˆæå†²åˆº - çªç ´1000 tokens/s
åŸºäº853.7 tokens/sçš„æˆåŠŸï¼Œè¿›è¡Œæœ€åä¼˜åŒ–
"""

import os
import sys
import time
import json
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass
from functools import partial

# æé™JAXç¯å¢ƒè®¾ç½®
os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'
os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.98'  # æé™å†…å­˜ä½¿ç”¨
os.environ['JAX_ENABLE_X64'] = 'false'
os.environ['XLA_PYTHON_CLIENT_ALLOCATOR'] = 'platform'
os.environ['XLA_FLAGS'] = '--xla_gpu_enable_fast_math=true'  # å¯ç”¨å¿«é€Ÿæ•°å­¦

# å¯¼å…¥JAXç›¸å…³åŒ…
try:
    import jax
    import jax.numpy as jnp
    from jax import random, pmap, devices, device_count
    from jax.sharding import Mesh, PartitionSpec, NamedSharding
    from jax.experimental import mesh_utils
    import flax.linen as nn
    from flax import jax_utils
    import numpy as np
    print(f"âœ… JAX {jax.__version__} æé™æ¨¡å¼åŠ è½½")
except ImportError as e:
    print(f"âŒ JAXå¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

@dataclass
class UltimateSpeedConfig:
    """ç»ˆæé€Ÿåº¦é…ç½®"""
    vocab_size: int = 50257
    n_positions: int = 2048
    n_embd: int = 1600
    n_layer: int = 48
    n_head: int = 25
    dropout: float = 0.0
    use_bias: bool = True
    
    def get_param_count(self) -> int:
        embed_params = self.vocab_size * self.n_embd + self.n_positions * self.n_embd
        layer_params = (4 * self.n_embd * self.n_embd + 8 * self.n_embd * self.n_embd + 4 * self.n_embd)
        total_params = embed_params + self.n_layer * layer_params + self.vocab_size * self.n_embd
        return total_params

class UltimateSpeedAttention(nn.Module):
    """ç»ˆæé€Ÿåº¦æ³¨æ„åŠ› - æ‰€æœ‰ä¼˜åŒ–æŠ€å·§"""
    config: UltimateSpeedConfig
    
    def setup(self):
        self.c_attn = nn.Dense(3 * self.config.n_embd, use_bias=self.config.use_bias)
        self.c_proj = nn.Dense(self.config.n_embd, use_bias=self.config.use_bias)
        self.n_head = self.config.n_head
        self.n_embd = self.config.n_embd
        self.head_dim = self.n_embd // self.n_head
        self.scale = 1.0 / jnp.sqrt(self.head_dim)
        
    def __call__(self, x, mask=None, training=False):
        B, T, C = x.shape
        
        # è¶…çº§ä¼˜åŒ–çš„QKVè®¡ç®—
        qkv = self.c_attn(x)
        qkv = qkv.reshape(B, T, 3, self.n_head, self.head_dim)
        
        # ç›´æ¥åˆ†å‰²å’Œé‡æ’ï¼Œé¿å…é¢å¤–æ“ä½œ
        q = qkv[:, :, 0, :, :].transpose(0, 2, 1, 3)  # (B, nh, T, hd)
        k = qkv[:, :, 1, :, :].transpose(0, 2, 1, 3)
        v = qkv[:, :, 2, :, :].transpose(0, 2, 1, 3)
        
        # æé™ä¼˜åŒ–çš„æ³¨æ„åŠ›è®¡ç®—
        # ä½¿ç”¨æ›´å¤§åˆ†å—ä»¥å‡å°‘å¾ªç¯å¼€é”€
        chunk_size = min(1024, T)  # æ›´å¤§çš„åˆ†å—
        
        if T <= chunk_size:
            # å•å—å¤„ç†ï¼Œæœ€å¿«è·¯å¾„
            scores = (q @ k.transpose(0, 1, 3, 2)) * self.scale
            if mask is not None:
                scores = jnp.where(mask, scores, -1e9)
            attn = jax.nn.softmax(scores, axis=-1)
            y = attn @ v
        else:
            # åˆ†å—å¤„ç†ï¼Œå¤§åºåˆ—
            outputs = []
            for i in range(0, T, chunk_size):
                end_i = min(i + chunk_size, T)
                q_chunk = q[:, :, i:end_i, :]
                
                scores = jnp.einsum('bnid,bnjd->bnij', q_chunk, k) * self.scale
                if mask is not None:
                    mask_chunk = mask[:, :, i:end_i, :]
                    scores = jnp.where(mask_chunk, scores, -1e9)
                
                attn = jax.nn.softmax(scores, axis=-1)
                output_chunk = jnp.einsum('bnij,bnjd->bnid', attn, v)
                outputs.append(output_chunk)
            
            y = jnp.concatenate(outputs, axis=2)
        
        # æœ€ç»ˆé‡æ’å’ŒæŠ•å½±
        y = y.transpose(0, 2, 1, 3).reshape(B, T, C)
        return self.c_proj(y)

class UltimateSpeedMLP(nn.Module):
    """ç»ˆæé€Ÿåº¦MLP"""
    config: UltimateSpeedConfig
    
    def setup(self):
        self.c_fc = nn.Dense(4 * self.config.n_embd, use_bias=self.config.use_bias)
        self.c_proj = nn.Dense(self.config.n_embd, use_bias=self.config.use_bias)
    
    def __call__(self, x, training=False):
        # æç®€MLPè·¯å¾„
        x = self.c_fc(x)
        x = jax.nn.gelu(x, approximate=True)  # å¿«é€Ÿè¿‘ä¼¼GELU
        return self.c_proj(x)

class UltimateSpeedBlock(nn.Module):
    """ç»ˆæé€Ÿåº¦Transformerå—"""
    config: UltimateSpeedConfig
    
    def setup(self):
        self.ln_1 = nn.LayerNorm()
        self.attn = UltimateSpeedAttention(self.config)
        self.ln_2 = nn.LayerNorm()
        self.mlp = UltimateSpeedMLP(self.config)
    
    def __call__(self, x, mask=None, training=False):
        # æœ€ä¼˜åŒ–çš„residualè·¯å¾„
        x = x + self.attn(self.ln_1(x), mask, training)
        x = x + self.mlp(self.ln_2(x), training)
        return x

class UltimateSpeedGPT(nn.Module):
    """ç»ˆæé€Ÿåº¦GPT"""
    config: UltimateSpeedConfig
    
    def setup(self):
        self.wte = nn.Embed(self.config.vocab_size, self.config.n_embd)
        self.wpe = nn.Embed(self.config.n_positions, self.config.n_embd)
        self.h = [UltimateSpeedBlock(self.config) for _ in range(self.config.n_layer)]
        self.ln_f = nn.LayerNorm()
    
    def __call__(self, input_ids, training=False):
        B, T = input_ids.shape
        
        # å¿«é€ŸåµŒå…¥
        token_embed = self.wte(input_ids)
        pos_embed = self.wpe(jnp.arange(T)[None, :])
        x = token_embed + pos_embed
        
        # é¢„è®¡ç®—maskï¼Œé¿å…é‡å¤è®¡ç®—
        mask = jnp.tril(jnp.ones((T, T), dtype=jnp.bool_))[None, None, :, :]
        
        # å¿«é€Ÿtransformerå±‚
        for block in self.h:
            x = block(x, mask, training)
        
        # å¿«é€Ÿè¾“å‡º
        x = self.ln_f(x)
        return x @ self.wte.embedding.T

class SpeedDemonEngine:
    """é€Ÿåº¦æ¶é­”å¼•æ“ - è¿½æ±‚æé™é€Ÿåº¦"""
    
    def __init__(self, config: UltimateSpeedConfig):
        self.config = config
        self.devices = jax.devices()
        
        print(f"ğŸ‘¹ é€Ÿåº¦æ¶é­”å¼•æ“å¯åŠ¨")
        print(f"   è®¾å¤‡: {len(self.devices)}x RTX 3090")
        print(f"   ç›®æ ‡: çªç ´1000 tokens/s!")
        
        self.mesh = self._create_optimized_mesh()
        self.model = UltimateSpeedGPT(config)
        self._init_parameters()
        self._compile_speed_functions()
    
    def _create_optimized_mesh(self):
        """åˆ›å»ºæœ€ä¼˜meshé…ç½®"""
        mesh_devices = mesh_utils.create_device_mesh((2, 2))
        mesh = Mesh(mesh_devices, axis_names=('data', 'model'))
        print(f"   Mesh: æœ€ä¼˜2x2é…ç½®")
        return mesh
    
    def _init_parameters(self):
        """å¿«é€Ÿå‚æ•°åˆå§‹åŒ–"""
        print("âš¡ å¿«é€Ÿå‚æ•°åˆå§‹åŒ–...")
        
        key = jax.random.PRNGKey(42)
        dummy_input = jnp.ones((1, 64), dtype=jnp.int32)
        
        start_time = time.time()
        self.params = self.model.init(key, dummy_input, training=False)
        init_time = time.time() - start_time
        
        param_count = sum(x.size for x in jax.tree_util.tree_leaves(self.params))
        print(f"   å‚æ•°: {param_count/1e6:.1f}M ({init_time:.1f}s)")
    
    def _compile_speed_functions(self):
        """ç¼–è¯‘è¶…çº§ä¼˜åŒ–å‡½æ•°"""
        print("ğŸš€ ç¼–è¯‘é€Ÿåº¦æ¶é­”å‡½æ•°...")
        
        with self.mesh:
            input_sharding = NamedSharding(self.mesh, PartitionSpec('data', None))
            output_sharding = NamedSharding(self.mesh, PartitionSpec('data', None))
            
            @partial(
                jax.jit, 
                in_shardings=(None, input_sharding), 
                out_shardings=output_sharding,
                static_argnums=()
            )
            def speed_demon_forward(params, input_ids):
                return self.model.apply(params, input_ids, training=False)
            
            self.forward_fn = speed_demon_forward
            print("   é€Ÿåº¦æ¶é­”å‡½æ•°å°±ç»ª!")
    
    def speed_test(self, batch_size, seq_len, num_runs=5):
        """é€Ÿåº¦æ¶é­”æµ‹è¯•"""
        total_tokens = batch_size * seq_len
        print(f"\nğŸ‘¹ é€Ÿåº¦æ¶é­”æµ‹è¯•: {batch_size}x{seq_len} = {total_tokens:,} tokens")
        
        # åˆ›å»ºæœ€ä¼˜æµ‹è¯•æ•°æ®
        key = jax.random.PRNGKey(42)
        input_ids = jax.random.randint(key, (batch_size, seq_len), 0, self.config.vocab_size)
        
        with self.mesh:
            input_sharding = NamedSharding(self.mesh, PartitionSpec('data', None))
            input_ids = jax.device_put(input_ids, input_sharding)
        
        # æç®€é¢„çƒ­
        print("ğŸ”¥ æ¶é­”é¢„çƒ­...")
        logits = self.forward_fn(self.params, input_ids)
        jax.block_until_ready(logits)
        
        # é€Ÿåº¦æ¶é­”åŸºå‡†æµ‹è¯•
        print(f"âš¡ æ¶é­”å†²åˆº ({num_runs}æ¬¡)...")
        times = []
        
        for i in range(num_runs):
            start_time = time.time()
            logits = self.forward_fn(self.params, input_ids)
            jax.block_until_ready(logits)
            end_time = time.time()
            
            time_taken = end_time - start_time
            throughput = total_tokens / time_taken
            times.append(time_taken)
            
            print(f"   å†²åˆº {i+1}: {time_taken*1000:.1f}ms â†’ {throughput:.1f} tokens/s")
        
        # æ¶é­”çº§ç»“æœ
        best_time = min(times)
        peak_throughput = total_tokens / best_time
        mean_throughput = total_tokens / np.mean(times)
        
        print(f"\nğŸ‘¹ æ¶é­”ç»“æœ:")
        print(f"   æ¶é­”é€Ÿåº¦: {peak_throughput:.1f} tokens/s")
        print(f"   å¹³å‡é€Ÿåº¦: {mean_throughput:.1f} tokens/s")
        print(f"   æ¶é­”æ—¶é—´: {best_time*1000:.1f}ms")
        
        return {
            'batch_size': batch_size,
            'seq_len': seq_len,
            'total_tokens': total_tokens,
            'peak_throughput': peak_throughput,
            'mean_throughput': mean_throughput,
            'best_time': best_time
        }

def main():
    """ä¸»å‡½æ•° - é€Ÿåº¦æ¶é­”æŒ‘æˆ˜"""
    print("ğŸ‘¹ é€Ÿåº¦æ¶é­”æŒ‘æˆ˜ - çªç ´1000 tokens/s")
    print("=" * 60)
    print("ğŸ¯ ç›®æ ‡: ä»853.7 â†’ 1000+ tokens/s")
    
    config = UltimateSpeedConfig()
    engine = SpeedDemonEngine(config)
    
    # é€Ÿåº¦æ¶é­”é…ç½® - åŸºäºæœ€ä½³ç»“æœä¼˜åŒ–
    demon_tests = [
        # åŸºäº64x512çš„æœ€ä½³ç»“æœï¼Œå°è¯•æ›´å¤§æ‰¹æ¬¡
        (64, 512),   # é‡ç°853.7 tokens/s
        (80, 512),   # çªç ´ç‚¹1
        (96, 512),   # çªç ´ç‚¹2
        (112, 512),  # çªç ´ç‚¹3
        (128, 512),  # ç»ˆææŒ‘æˆ˜
    ]
    
    results = []
    best_throughput = 0
    breakthrough = False
    
    for batch_size, seq_len in demon_tests:
        try:
            result = engine.speed_test(batch_size, seq_len, num_runs=5)
            results.append(result)
            
            current_throughput = result['peak_throughput']
            if current_throughput > best_throughput:
                best_throughput = current_throughput
            
            # æ£€æŸ¥æ˜¯å¦çªç ´1000
            if current_throughput >= 1000:
                print(f"\nğŸ‰ çªç ´1000 tokens/s! è¾¾åˆ° {current_throughput:.1f} tokens/s")
                breakthrough = True
            
            # å¦‚æœæ—¶é—´è¿‡é•¿å°±åœæ­¢
            if result['best_time'] > 60:  # è¶…è¿‡60ç§’
                print("â° æ—¶é—´è¿‡é•¿ï¼Œæ¶é­”ä¼‘æ¯")
                break
                
        except Exception as e:
            print(f"ğŸ’¥ é…ç½® {batch_size}x{seq_len} æŒ‘æˆ˜å¤±è´¥: {e}")
            # å†…å­˜ä¸è¶³ï¼Œåœæ­¢å¢åŠ 
            break
    
    # ä¿å­˜æ¶é­”ç»“æœ
    if results:
        results_file = Path("speed_demon_results.json")
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        print(f"\nğŸ‘¹ é€Ÿåº¦æ¶é­”æŒ‘æˆ˜å®Œæˆ!")
        print(f"   æ¶é­”æœ€é€Ÿ: {best_throughput:.1f} tokens/s")
        print(f"   æŒ‘æˆ˜æ¬¡æ•°: {len(results)}")
        print(f"   ç»“æœæ–‡ä»¶: {results_file}")
        
        # æ¶é­”æ’è¡Œæ¦œ
        print(f"\nğŸ† æ¶é­”æ’è¡Œæ¦œ:")
        sorted_results = sorted(results, key=lambda x: x['peak_throughput'], reverse=True)
        for i, result in enumerate(sorted_results):
            throughput = result['peak_throughput']
            config_str = f"{result['batch_size']}x{result['seq_len']}"
            print(f"   {i+1}. {config_str}: {throughput:.1f} tokens/s")
    
    if breakthrough:
        print(f"\nğŸ‰ æ¶é­”çªç ´æˆåŠŸ! 1000+ tokens/s è¾¾æˆ!")
    else:
        print(f"\nâš¡ æ¶é­”ç»§ç»­è¿›åŒ–ä¸­... å½“å‰æœ€ä½³: {best_throughput:.1f} tokens/s")

if __name__ == "__main__":
    main()
